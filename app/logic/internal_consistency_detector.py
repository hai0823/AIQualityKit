#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å†…éƒ¨ä¸€è‡´æ€§æ£€æµ‹å™¨ - æ£€æµ‹AIå›ç­”è‡ªèº«çš„é€»è¾‘ä¸€è‡´æ€§
ä¸ä¾èµ–å¤–éƒ¨å¼•æ–‡ï¼Œä¸“é—¨æ£€æµ‹ç­”æ¡ˆå†…éƒ¨çš„çŸ›ç›¾ã€é”™è¯¯å’Œé€»è¾‘é—®é¢˜
"""

import pandas as pd
import json
import asyncio
import aiohttp
import re
from typing import Dict, Any, List, Optional
import logging
from ..utils.api_client import create_api_client

logger = logging.getLogger(__name__)

class InternalConsistencyDetector:
    def __init__(self, provider: str = "deepseek", api_key: str = None, 
                 base_url: str = None, model: str = None, concurrent_limit: int = 10):
        """
        åˆå§‹åŒ–å†…éƒ¨ä¸€è‡´æ€§æ£€æµ‹å™¨
        
        Args:
            provider: APIæä¾›å•† ('alibaba', 'openai', 'deepseek')
            api_key: APIå¯†é’¥
            base_url: APIåŸºç¡€URLï¼ˆå¯é€‰ï¼‰
            model: æ¨¡å‹åç§°ï¼ˆå¯é€‰ï¼‰
            concurrent_limit: å¹¶å‘é™åˆ¶
        """
        self.provider = provider.lower()
        self.concurrent_limit = concurrent_limit
        
        # ä½¿ç”¨ç°æœ‰çš„APIå®¢æˆ·ç«¯
        self.api_client = create_api_client(provider, api_key, base_url, model)
        self.api_key = self.api_client.api_key
        self.base_url = self.api_client.base_url
        self.model = self.api_client.model
        
        if not self.api_key:
            raise ValueError(f"APIå¯†é’¥æœªè®¾ç½®ï¼Œè¯·æä¾›{provider} APIå¯†é’¥")
        
        print(f"ğŸ” å†…éƒ¨ä¸€è‡´æ€§æ£€æµ‹å™¨å¯åŠ¨")
        print(f"æ­£åœ¨ä½¿ç”¨æä¾›å•†: {self.provider}")
        print(f"æ­£åœ¨ä½¿ç”¨æ¨¡å‹: {self.model}")
        print(f"å¹¶å‘é™åˆ¶: {self.concurrent_limit}")

    def extract_clean_answer(self, raw_answer: str) -> str:
        """
        æå–çº¯å‡€çš„ç­”æ¡ˆå†…å®¹ï¼Œç§»é™¤æ€è€ƒè¿‡ç¨‹
        
        Args:
            raw_answer: åŸå§‹ç­”æ¡ˆï¼ˆå¯èƒ½åŒ…å«æ€è€ƒè¿‡ç¨‹ï¼‰
            
        Returns:
            æ¸…æ´çš„ç­”æ¡ˆå†…å®¹
        """
        # å¸¸è§çš„æ€è€ƒè¿‡ç¨‹æ ‡è®°æ¨¡å¼
        thinking_patterns = [
            r'<æ€è€ƒ>.*?</æ€è€ƒ>',
            r'<thinking>.*?</thinking>', 
            r'ã€æ€è€ƒè¿‡ç¨‹ã€‘.*?ã€å›ç­”ã€‘',
            r'æ€è€ƒè¿‡ç¨‹ï¼š.*?\n\n',
            r'è®©æˆ‘æ€è€ƒä¸€ä¸‹.*?\n\n',
            r'åˆ†æï¼š.*?\n\nå›ç­”ï¼š',
        ]
        
        clean_answer = raw_answer
        
        # ç§»é™¤æ€è€ƒè¿‡ç¨‹æ ‡è®°
        for pattern in thinking_patterns:
            clean_answer = re.sub(pattern, '', clean_answer, flags=re.DOTALL)
        
        # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
        clean_answer = re.sub(r'\n{3,}', '\n\n', clean_answer)
        clean_answer = clean_answer.strip()
        
        # å¦‚æœç»è¿‡æ¸…ç†åå†…å®¹å¤ªçŸ­ï¼Œå¯èƒ½è¿‡åº¦æ¸…ç†äº†ï¼Œè¿”å›åŸæ–‡
        if len(clean_answer) < len(raw_answer) * 0.3:
            return raw_answer.strip()
            
        return clean_answer

    def create_consistency_prompt(self, question: str, answer: str) -> str:
        """
        åˆ›å»ºå†…éƒ¨ä¸€è‡´æ€§æ£€æµ‹çš„æç¤ºè¯
        ä¸“æ³¨äºç­”æ¡ˆè‡ªèº«çš„é€»è¾‘ä¸€è‡´æ€§ï¼Œä¸ä¾èµ–å¤–éƒ¨å¼•æ–‡
        """
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é€»è¾‘ä¸€è‡´æ€§æ£€æµ‹ä¸“å®¶ã€‚

ã€æ ¸å¿ƒä»»åŠ¡ã€‘
æ£€æµ‹AIå›ç­”æ˜¯å¦å­˜åœ¨å†…éƒ¨é€»è¾‘çŸ›ç›¾ã€äº‹å®å†²çªæˆ–åŸºç¡€é”™è¯¯ã€‚
**é‡è¦ï¼šå®Œå…¨ä¸è€ƒè™‘å¤–éƒ¨å¼•æ–‡æˆ–å‚è€ƒèµ„æ–™ï¼Œåªæ£€æŸ¥ç­”æ¡ˆè‡ªèº«çš„å†…éƒ¨ä¸€è‡´æ€§ã€‚**

ã€æ£€æµ‹ç±»å‹ã€‘
1. æ— é—®é¢˜ï¼šç­”æ¡ˆé€»è¾‘æ¸…æ™°ï¼Œå‰åä¸€è‡´ï¼Œæ— æ˜æ˜¾é”™è¯¯
2. å‰åçŸ›ç›¾ï¼šç­”æ¡ˆå†…éƒ¨æåˆ°çš„åŒä¸€äº‹å®æˆ–è§‚ç‚¹å‰åä¸ä¸€è‡´
3. é€»è¾‘é”™è¯¯ï¼šæ¨ç†é“¾æ¡æœ‰æ¼æ´ï¼Œç»“è®ºä¸å‰æä¸ç¬¦ï¼Œé€»è¾‘è·³è·ƒ
4. åŸºç¡€é”™è¯¯ï¼šç®€å•çš„æ•°å­¦è®¡ç®—é”™è¯¯ã€å¸¸è¯†æ€§é”™è¯¯ã€æ˜æ˜¾çš„äº‹å®æ€§é”™è¯¯
5. è‡ªç›¸çŸ›ç›¾ï¼šç­”æ¡ˆå†…éƒ¨è§‚ç‚¹æˆ–ç«‹åœºç›¸äº’å†²çª

ã€é‡ç‚¹å…³æ³¨ã€‘
- æ•°å­—æ¯”è¾ƒé”™è¯¯ï¼ˆå¦‚"11.9å¤§äº13"ï¼‰
- æ—¶é—´é€»è¾‘é”™è¯¯ï¼ˆå¦‚"2020å¹´æ¯”2023å¹´æ™š"ï¼‰
- å› æœå…³ç³»æ··ä¹±
- åŒä¸€æ¦‚å¿µçš„ä¸åŒå®šä¹‰æˆ–æè¿°
- è®¡ç®—è¿‡ç¨‹ä¸ç»“æœä¸ç¬¦
- è¿ååŸºæœ¬å¸¸è¯†çš„è¡¨è¿°

ã€è¾“å‡ºæ ¼å¼ã€‘
çŠ¶æ€ï¼š[æ— é—®é¢˜/å‰åçŸ›ç›¾/é€»è¾‘é”™è¯¯/åŸºç¡€é”™è¯¯/è‡ªç›¸çŸ›ç›¾]
é—®é¢˜æè¿°ï¼š[å…·ä½“æŒ‡å‡ºå­˜åœ¨çš„é—®é¢˜ï¼Œå¦‚æœæ— é—®é¢˜åˆ™è¯´æ˜æ£€æŸ¥è¦ç‚¹]
å…·ä½“ä½ç½®ï¼š[æŒ‡å‡ºé—®é¢˜å‡ºç°çš„å…·ä½“ä½ç½®æˆ–å¥å­]"""

        user_prompt = f"""ã€é—®é¢˜ã€‘
{question}

ã€AIå›ç­”ã€‘
{answer}

è¯·ä¸¥æ ¼æŒ‰ç…§è¦æ±‚æ ¼å¼æ£€æµ‹è¿™ä¸ªå›ç­”çš„å†…éƒ¨ä¸€è‡´æ€§ï¼š"""

        return f"{system_prompt}\n\n{user_prompt}"

    def _parse_consistency_result(self, response_text: str, entry_id: int) -> tuple[str, str, str]:
        """
        è§£æä¸€è‡´æ€§æ£€æµ‹ç»“æœ
        
        Args:
            response_text: APIè¿”å›çš„åˆ†ææ–‡æœ¬
            entry_id: æ•°æ®ID
            
        Returns:
            (status, description, location): çŠ¶æ€ã€é—®é¢˜æè¿°ã€å…·ä½“ä½ç½®çš„å…ƒç»„
        """
        response_text = response_text.strip()
        
        # åˆå§‹åŒ–è¿”å›å€¼
        status = "æ— é—®é¢˜"
        description = "ç­”æ¡ˆé€»è¾‘ä¸€è‡´ï¼Œæ— æ˜æ˜¾é—®é¢˜"
        location = ""
        
        # æå–çŠ¶æ€
        if "çŠ¶æ€ï¼š" in response_text:
            status_match = re.search(r'çŠ¶æ€ï¼š\s*([^\\n]+)', response_text)
            if status_match:
                status = status_match.group(1).strip()
        
        # æ ¹æ®å…³é”®è¯è¯†åˆ«çŠ¶æ€
        if "å‰åçŸ›ç›¾" in response_text:
            status = "å‰åçŸ›ç›¾"
        elif "é€»è¾‘é”™è¯¯" in response_text:
            status = "é€»è¾‘é”™è¯¯"
        elif "åŸºç¡€é”™è¯¯" in response_text:
            status = "åŸºç¡€é”™è¯¯"
        elif "è‡ªç›¸çŸ›ç›¾" in response_text:
            status = "è‡ªç›¸çŸ›ç›¾"
        elif "æ— é—®é¢˜" in response_text:
            status = "æ— é—®é¢˜"
        
        # æå–é—®é¢˜æè¿°
        if "é—®é¢˜æè¿°ï¼š" in response_text:
            desc_match = re.search(r'é—®é¢˜æè¿°ï¼š\s*([^\\n]+(?:\\n[^\\n]*)*?)(?=å…·ä½“ä½ç½®ï¼š|$)', response_text, re.MULTILINE)
            if desc_match:
                description = desc_match.group(1).strip()
        
        # æå–å…·ä½“ä½ç½®
        if "å…·ä½“ä½ç½®ï¼š" in response_text:
            loc_match = re.search(r'å…·ä½“ä½ç½®ï¼š\s*([^\\n]+(?:\\n[^\\n]*)*?)(?=$)', response_text, re.MULTILINE)
            if loc_match:
                location = loc_match.group(1).strip()
        
        return status, description, location

    async def analyze_single_item(self, session: aiohttp.ClientSession, item: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æå•ä¸ªæ•°æ®é¡¹çš„å†…éƒ¨ä¸€è‡´æ€§"""
        try:
            rank = item.get('rank', 0)
            
            # æå–é—®é¢˜å’ŒåŸå§‹ç­”æ¡ˆ
            question = str(item.get('æ¨¡å‹prompt', '')) if pd.notna(item.get('æ¨¡å‹prompt', '')) else ""
            raw_answer = str(item.get('ç­”æ¡ˆ', '')) if pd.notna(item.get('ç­”æ¡ˆ', '')) else ""
            
            # æ¸…ç†ç­”æ¡ˆï¼Œç§»é™¤æ€è€ƒè¿‡ç¨‹
            clean_answer = self.extract_clean_answer(raw_answer)
            
            # è°ƒè¯•ä¿¡æ¯
            print(f"ğŸ” ç¬¬{rank}æ¡æ•°æ®æå–ç»“æœ:")
            print(f"  é—®é¢˜é•¿åº¦: {len(question)}")
            print(f"  åŸå§‹ç­”æ¡ˆé•¿åº¦: {len(raw_answer)}")
            print(f"  æ¸…ç†åç­”æ¡ˆé•¿åº¦: {len(clean_answer)}")
            
            # æ£€æŸ¥å¿…è¦æ•°æ®
            if not question.strip() or not clean_answer.strip():
                return {
                    'rank': rank,
                    'api_success': False,
                    'error': 'ç¼ºå°‘å¿…è¦çš„é—®é¢˜æˆ–ç­”æ¡ˆæ•°æ®',
                    'status': 'unknown',
                    'description': '',
                    'location': ''
                }
            
            # åˆ›å»ºæ£€æµ‹æç¤ºè¯
            prompt = self.create_consistency_prompt(question, clean_answer)
            
            # è°ƒç”¨API
            result = await self.api_client.call_async(session, prompt, temperature=0.1, max_tokens=4000)
            
            if result['success']:
                try:
                    content = result['content'].strip()
                    
                    # è§£æå“åº”
                    status, description, location = self._parse_consistency_result(content, rank)
                    
                    return {
                        'rank': rank,
                        'api_success': True,
                        'question': question,
                        'clean_answer': clean_answer,
                        'original_answer_length': len(raw_answer),
                        'clean_answer_length': len(clean_answer),
                        'status': status,
                        'description': description,
                        'location': location,
                        'raw_response': content
                    }
                    
                except Exception as e:
                    return {
                        'rank': rank,
                        'api_success': False,
                        'error': f'å“åº”è§£æå¤±è´¥: {e}',
                        'raw_response': content if 'content' in locals() else '',
                        'status': 'unknown',
                        'description': f'è§£æå¼‚å¸¸: {str(e)}',
                        'location': ''
                    }
            else:
                return {
                    'rank': rank,
                    'api_success': False,
                    'error': result['error'],
                    'status': 'unknown',
                    'description': '',
                    'location': ''
                }
                
        except Exception as e:
            return {
                'rank': item.get('rank', 0),
                'api_success': False,
                'error': f'åˆ†æå¼‚å¸¸: {str(e)}',
                'status': 'unknown',
                'description': '',
                'location': ''
            }

    async def batch_analyze_excel(self, file_content: bytes, num_samples: int = None, 
                                 specific_rank: int = None, start_from: int = None) -> List[Dict[str, Any]]:
        """æ‰¹é‡åˆ†æExcelæ–‡ä»¶ä¸­çš„å†…éƒ¨ä¸€è‡´æ€§é—®é¢˜"""
        try:
            # è¯»å–Excelæ–‡ä»¶
            import io
            df = pd.read_excel(io.BytesIO(file_content))
            print(f"ğŸ“Š Excelæ–‡ä»¶è¯»å–æˆåŠŸï¼Œå…±{len(df)}è¡Œæ•°æ®")
            print(f"ğŸ“‹ æ£€æµ‹åˆ°çš„åˆ—å: {df.columns.tolist()}")
            
            # æ ¹æ®å‚æ•°ç­›é€‰æ•°æ®
            if specific_rank:
                if specific_rank <= len(df):
                    df = df.iloc[[specific_rank - 1]]
                    print(f"ğŸ” åˆ†æç¬¬{specific_rank}æ¡æ•°æ®")
                else:
                    raise ValueError(f"æŒ‡å®šçš„rank {specific_rank} è¶…å‡ºæ•°æ®èŒƒå›´ï¼ˆå…±{len(df)}è¡Œï¼‰")
            elif start_from:
                start_idx = start_from - 1
                if num_samples:
                    end_idx = start_idx + num_samples
                    df = df.iloc[start_idx:end_idx]
                    print(f"ğŸ” åˆ†æä»ç¬¬{start_from}æ¡å¼€å§‹çš„{num_samples}æ¡æ•°æ®")
                else:
                    df = df.iloc[start_idx:]
                    print(f"ğŸ” åˆ†æä»ç¬¬{start_from}æ¡åˆ°ç»“å°¾çš„æ•°æ®")
            elif num_samples:
                df = df.head(num_samples)
                print(f"ğŸ” åˆ†æå‰{num_samples}æ¡æ•°æ®")
            else:
                print(f"ğŸ” åˆ†ææ‰€æœ‰{len(df)}æ¡æ•°æ®")
            
            # ä¸ºæ¯è¡Œæ•°æ®æ·»åŠ rankä¿¡æ¯
            data_items = []
            for idx, row in df.iterrows():
                item = row.to_dict()
                item['rank'] = idx + 1  # rankä»1å¼€å§‹
                data_items.append(item)
            
            # å¼‚æ­¥å¹¶å‘åˆ†æ
            semaphore = asyncio.Semaphore(self.concurrent_limit)
            
            async def analyze_with_semaphore(item):
                async with semaphore:
                    async with aiohttp.ClientSession() as session:
                        return await self.analyze_single_item(session, item)
            
            print(f"ğŸ”„ å¼€å§‹å¹¶å‘å†…éƒ¨ä¸€è‡´æ€§æ£€æµ‹ï¼Œå¹¶å‘é™åˆ¶: {self.concurrent_limit}")
            tasks = [analyze_with_semaphore(item) for item in data_items]
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # å¤„ç†å¼‚å¸¸ç»“æœ
            final_results = []
            for i, result in enumerate(results):
                if isinstance(result, Exception):
                    final_results.append({
                        'rank': data_items[i].get('rank', i + 1),
                        'api_success': False,
                        'error': f'åˆ†æå¼‚å¸¸: {str(result)}',
                        'status': 'unknown',
                        'description': '',
                        'location': ''
                    })
                else:
                    final_results.append(result)
            
            print(f"âœ… å†…éƒ¨ä¸€è‡´æ€§æ£€æµ‹å®Œæˆï¼Œå…±{len(final_results)}æ¡ç»“æœ")
            return final_results
            
        except Exception as e:
            print(f"âŒ æ‰¹é‡åˆ†æå¤±è´¥: {str(e)}")
            raise

    def save_results(self, results: List[Dict[str, Any]], output_path: str):
        """ä¿å­˜åˆ†æç»“æœ"""
        try:
            import os
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            
            # å¯¼å…¥æ’åºåŠŸèƒ½å¹¶å¯¹ç»“æœæ’åº
            from .json_rank_sorter import sort_by_rank
            sorted_results = sort_by_rank(results)
            
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(sorted_results, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… å†…éƒ¨ä¸€è‡´æ€§æ£€æµ‹ç»“æœå·²ä¿å­˜åˆ°: {output_path}ï¼ˆå·²æŒ‰rankæ’åºï¼‰")
            
        except Exception as e:
            print(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {str(e)}")

    def generate_summary(self, results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ç”Ÿæˆåˆ†ææ‘˜è¦"""
        total_count = len(results)
        success_count = sum(1 for r in results if r.get('api_success', False))
        failed_count = total_count - success_count
        
        # ç»Ÿè®¡é—®é¢˜ç±»åˆ«
        status_stats = {}
        no_problem_count = 0
        
        for result in results:
            if result.get('api_success'):
                status = result.get('status', 'unknown')
                status_stats[status] = status_stats.get(status, 0) + 1
                
                if status == 'æ— é—®é¢˜':
                    no_problem_count += 1
        
        problem_count = success_count - no_problem_count
        
        return {
            'total_count': total_count,
            'success_count': success_count,
            'failed_count': failed_count,
            'problem_count': problem_count,
            'no_problem_count': no_problem_count,
            'problem_rate': problem_count / success_count if success_count > 0 else 0,
            'status_distribution': status_stats,
            'analysis_summary': {
                'å‰åçŸ›ç›¾': status_stats.get('å‰åçŸ›ç›¾', 0),
                'é€»è¾‘é”™è¯¯': status_stats.get('é€»è¾‘é”™è¯¯', 0),
                'åŸºç¡€é”™è¯¯': status_stats.get('åŸºç¡€é”™è¯¯', 0),
                'è‡ªç›¸çŸ›ç›¾': status_stats.get('è‡ªç›¸çŸ›ç›¾', 0),
                'æ— é—®é¢˜': status_stats.get('æ— é—®é¢˜', 0)
            }
        }