#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ–¹æ¡ˆ1ç™¾ç‚¼ç‰ˆï¼šä½¿ç”¨å®Œæ•´ç­”æ¡ˆå†…å®¹+ç™¾ç‚¼APIåˆ†æå¼•ç”¨å…³ç³»
"""

import pandas as pd
import json
import requests
import aiohttp
import asyncio
import os
import re
from typing import Dict, List, Any
import time
from ..utils.api_client import create_api_client


class Method1BailianAnalyzer:
    def __init__(self, concurrent_limit: int = 50, api_key: str = None, provider: str = "alibaba",
                 base_url: str = None, model: str = None):
        """
        åˆå§‹åŒ–å¼•æ–‡åˆ†æå™¨ï¼Œæ”¯æŒå¤šä¸ªAPIæä¾›å•†
        
        Args:
            concurrent_limit: å¹¶å‘é™åˆ¶
            api_key: APIå¯†é’¥
            provider: APIæä¾›å•† ('alibaba', 'openai', 'deepseek', 'nuwaapi')
            base_url: APIåŸºç¡€URLï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨æä¾›å•†çš„é»˜è®¤URLï¼‰
            model: æ¨¡å‹åç§°ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨æä¾›å•†çš„æ¨èæ¨¡å‹ï¼‰
        """
        self.provider = provider.lower()
        self.concurrent_limit = concurrent_limit
        
        # é…ç½®APIæä¾›å•†
        self._configure_provider(api_key, base_url, model)
        
        print(f"æ­£åœ¨ä½¿ç”¨æä¾›å•†: {self.provider}")
        print(f"æ­£åœ¨ä½¿ç”¨æ¨¡å‹: {self.model}")
        print(f"å¹¶å‘é™åˆ¶: {self.concurrent_limit}æ¡")

        if not self.api_key:
            print(f"è­¦å‘Šï¼šæœªæ‰¾åˆ°APIå¯†é’¥ï¼Œæ— æ³•è°ƒç”¨{self.provider} API")
    
    def _configure_provider(self, api_key: str, base_url: str, model: str):
        """é…ç½®ä¸åŒçš„APIæä¾›å•†"""
        # ä¿®æ­£NUWA_KEYç¯å¢ƒå˜é‡å
        if self.provider == "nuwaapi":
            api_key = api_key or os.getenv('NUWA_KEY')
        
        # ä½¿ç”¨é€šç”¨APIå®¢æˆ·ç«¯
        self.api_client = create_api_client(self.provider, api_key, base_url, model)
        
        # ä¿æŒå…¼å®¹æ€§
        self.api_key = self.api_client.api_key
        self.api_ep = self.api_client.base_url
        self.model = self.api_client.model

    def count_chars(self, text: str) -> int:
        """ç®€å•çš„å­—ç¬¦è®¡æ•°ä¼°ç®—token"""
        # ä¸­æ–‡å¤§çº¦1.5å­—ç¬¦=1tokenï¼Œè‹±æ–‡çº¦4å­—ç¬¦=1token
        chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', text))
        other_chars = len(text) - chinese_chars
        estimated_tokens = int(chinese_chars / 1.5 + other_chars / 4)
        return estimated_tokens

    def load_data(self, excel_path: str) -> pd.DataFrame:
        """åŠ è½½Excelæ•°æ®"""
        try:
            df = pd.read_excel(excel_path)
            print(f"æˆåŠŸåŠ è½½Excelæ•°æ®ï¼š{len(df)}è¡Œ")
            return df
        except Exception as e:
            print(f"åŠ è½½Excelæ–‡ä»¶å¤±è´¥ï¼š{e}")
            return None

    def extract_citations(self, text: str) -> List[int]:
        """ä»æ–‡æœ¬ä¸­æå–å¼•ç”¨æ ‡è®°"""
        citations = []
        pattern = r'\[citation:(\d+)\]'
        matches = re.findall(pattern, text)
        for match in matches:
            citations.append(int(match))
        return sorted(list(set(citations)))

    def prepare_analysis_prompt(self, question: str, answer: str, citations_dict: Dict[int, str]) -> str:
        """å‡†å¤‡åˆ†æpromptï¼ˆå®Œæ•´ç‰ˆæœ¬ï¼Œä¸æˆªæ–­ï¼‰"""
        used_citations = self.extract_citations(answer)

        prompt_start = f"""è¯·åˆ†æä»¥ä¸‹é—®ç­”å†…å®¹ä¸­å¼•ç”¨ä¸å¼•æ–‡çš„åŒ¹é…å…³ç³»ï¼š

ã€å®Œæ•´ç­”æ¡ˆå†…å®¹ï¼ˆåŒ…å«æ€è€ƒè¿‡ç¨‹å’Œå›ç­”å†…å®¹ï¼‰ã€‘
{answer}

ã€ç­”æ¡ˆä¸­ä½¿ç”¨çš„å¼•ç”¨æ ‡è®°ã€‘
{used_citations}

ã€å¯ç”¨å¼•æ–‡å†…å®¹ã€‘
"""

        citations_text = ""
        # æ˜¾ç¤ºæ‰€æœ‰è¢«ä½¿ç”¨çš„å¼•æ–‡ï¼Œå®Œæ•´å†…å®¹
        for citation_num in used_citations:
            if citation_num in citations_dict:
                cite_text = citations_dict[citation_num]
                citations_text += f"å¼•æ–‡{citation_num}ï¼š{cite_text}\n\n"
            else:
                citations_text += f"å¼•æ–‡{citation_num}ï¼šï¼ˆæœªæ‰¾åˆ°å¯¹åº”å†…å®¹ï¼‰\n\n"

        analysis_requirements = '''ã€åˆ†æè¦æ±‚ã€‘
ä½ æ˜¯ä¸€ä¸ªä¸¥è°¨çš„æ–‡æœ¬åˆ†æä¸“å®¶ã€‚

ğŸš¨ æ ¸å¿ƒè§„åˆ™ï¼šåªè¾“å‡ºåŒ…å«[citation:x]æ ‡è®°çš„å¥å­ï¼æ²¡æœ‰å¼•ç”¨æ ‡è®°çš„å¥å­ç»å¯¹ä¸èƒ½å‡ºç°åœ¨JSONè¾“å‡ºä¸­ï¼

ä½ çš„ä»»åŠ¡ï¼šåˆ†æå®Œæ•´ç­”æ¡ˆå†…å®¹ï¼ˆåŒ…å«æ€è€ƒè¿‡ç¨‹å’Œå›ç­”å†…å®¹ï¼‰ä¸­æ‰€æœ‰åŒ…å«å¼•ç”¨æ ‡è®°[citation:x]çš„å¥å­ï¼Œå®Œå…¨è·³è¿‡æ²¡æœ‰å¼•ç”¨æ ‡è®°çš„å¥å­ã€‚

**é‡è¦è§„åˆ™ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰**ï¼š
- **å¼•ç”¨è¾¹ç•Œè¯†åˆ«**ï¼šå¼•ç”¨æ ‡è®°[citation:x]çš„ä½œç”¨èŒƒå›´ä¸¥æ ¼ä»¥å¥å·ï¼ˆã€‚ï¼‰ã€æ¢è¡Œç¬¦ã€æ®µè½åˆ†éš”ç¬¦ä¸ºè¾¹ç•Œï¼Œç»å¯¹ä¸èƒ½è·¨è¶Šè¿™äº›è¾¹ç•Œ
- **é€å¥ç‹¬ç«‹åˆ†æ**ï¼šå¿…é¡»å°†æ–‡æœ¬æŒ‰å¥å·ï¼ˆã€‚ï¼‰æ‹†åˆ†ä¸ºç‹¬ç«‹å¥å­ï¼Œæ¯ä¸ªå¥å­å•ç‹¬åˆ¤æ–­æ˜¯å¦åŒ…å«å¼•ç”¨æ ‡è®°
- **æ— å¼•ç”¨æ ‡è®°=è·³è¿‡**ï¼šå¦‚æœä¸€ä¸ªå¥å­å†…éƒ¨æ²¡æœ‰[citation:x]æ ‡è®°ï¼Œæ— è®ºå…¶å‰åå¥å­æ˜¯å¦æœ‰å¼•ç”¨ï¼Œéƒ½å¿…é¡»å®Œå…¨è·³è¿‡è¯¥å¥å­
- **ä¸¥ç¦è·¨å¥å…³è”**ï¼šç»å¯¹ä¸èƒ½å°†å‰ä¸€å¥å­çš„å¼•ç”¨æ ‡è®°åº”ç”¨åˆ°åç»­æ²¡æœ‰å¼•ç”¨æ ‡è®°çš„å¥å­ä¸Š
- **åªè¾“å‡ºä¸¤ç§ç»“æœ**ï¼šåˆ¤æ–­åªå­˜åœ¨ä¸€è‡´æˆ–ä¸ä¸€è‡´ä¸¤ç§ç»“æœã€‚å¦‚æœå¼•ç”¨é‡Œæœ‰ä¸€å¤„å¯ä»¥è¢«åˆ¤æ–­ä¸ºä¸ä¸€è‡´å°±ç›´æ¥åˆ¤å®šä¸ºä¸ä¸€è‡´

è¯·éµå¾ªä»¥ä¸‹æ­¥éª¤å’Œè§„åˆ™ï¼š

1.  **é€å¥æ‹†åˆ†**ï¼šå°†ã€å®Œæ•´ç­”æ¡ˆå†…å®¹ã€‘æ‹†åˆ†ä¸ºç‹¬ç«‹çš„è§‚ç‚¹æˆ–å¥å­ï¼Œåœ¨æ€è€ƒè¿‡ç¨‹å’Œå›ç­”å†…å®¹ä¸¤éƒ¨åˆ†ä¸­éƒ½è¦æŸ¥æ‰¾ã€‚
2.  **é€å¥åˆ†æ**ï¼šå¯¹äºæ¯ä¸€ä¸ªç‹¬ç«‹çš„è§‚ç‚¹æˆ–å¥å­ï¼š
    a. **é¦–å…ˆæ£€æŸ¥**ï¼šè¯¥å¥å­æ˜¯å¦åŒ…å«å¼•ç”¨æ ‡è®° `[citation:x]`ã€‚å¦‚æœæ²¡æœ‰ä»»ä½•å¼•ç”¨æ ‡è®°ï¼Œç«‹å³è·³è¿‡è¯¥å¥å­ï¼Œä¸è¿›è¡Œåˆ†æã€‚
    b. **ç²¾ç¡®åˆ’å®šå¼•ç”¨èŒƒå›´**ï¼šå¼•ç”¨æ ‡è®°ä»…å¯¹å¼•ç”¨æ ‡è®°åˆ—ä¸­ä½ç½®**ä¹‹å‰**çš„å†…å®¹èµ·ä½œç”¨ã€‚æ ‡ç‚¹å·åæˆ–æ–°å¥å­å¼€å§‹åçš„å†…å®¹ä¸åœ¨å¼•ç”¨èŒƒå›´å†…ã€‚
    c. å¦‚æœæœ‰å¼•ç”¨æ ‡è®°ï¼Œåœ¨å¯¹åº”çš„ `å¼•æ–‡x` ä¸­æŸ¥æ‰¾æ”¯æŒæ€§è¯æ®ã€‚
    d. **ä¸¥æ ¼åˆ¤æ–­**ï¼š
        (1) äº‹å®ä¸€è‡´æ€§
            * å…³é”®æ•°æ®ï¼ˆå¹´ä»½ã€æ•°å€¼ã€ç»Ÿè®¡ç»“æœï¼‰æ˜¯å¦å®Œå…¨åŒ¹é…å¼•æ–‡ã€‚
            * ä¸“ä¸šæœ¯è¯­å®šä¹‰æ˜¯å¦ä¸å¼•æ–‡åŸæ–‡ä¸€è‡´ï¼ˆå¦‚"é€ è¡€å¹²ç»†èƒç§»æ¤"â‰ "å¹²ç»†èƒç–—æ³•"ï¼‰ã€‚
            * æ¡ˆä¾‹/äº‹ä»¶æè¿°æ˜¯å¦æ— è™šæ„æˆ–ç¯¡æ”¹ï¼ˆå¦‚å¼•æ–‡æœªæ"æ·‹å·´ç˜¤æ²»ç–—",AIä¸å¾—æ·»åŠ ï¼‰ã€‚
        (2) å†…å®¹å®Œæ•´æ€§
            * AIæ˜¯å¦é—æ¼å¼•æ–‡çš„å…³é”®é™åˆ¶æ¡ä»¶ï¼ˆå¦‚"éœ€é…åˆåŒ–ç–—"è¢«çœç•¥ï¼‰ã€‚
            * æ˜¯å¦æ“…è‡ªæ‰©å±•å¼•æ–‡èŒƒå›´ï¼ˆå¦‚å¼•æ–‡ä»…æ”¯æŒ"ç™½è¡€ç—…",AIæ·»åŠ "å†ç”Ÿéšœç¢æ€§è´«è¡€"ï¼‰ã€‚
            * å¼•æ–‡ç»“è®ºçš„é€‚ç”¨è¾¹ç•Œæ˜¯å¦è¢«çªç ´ï¼ˆå¦‚"éƒ¨åˆ†æœ‰æ•ˆ"è¢«æ”¹ä¸º"æ™®éæœ‰æ•ˆ"ï¼‰ã€‚
        (3) è¯­ä¹‰åŒ¹é…åº¦
            * æ ¸å¿ƒè®ºç‚¹é€»è¾‘é“¾æ˜¯å¦ä¸å¼•æ–‡ä¸€è‡´ï¼ˆå¦‚"ç”Ÿæˆç–¾ç—…ç»†èƒâ†’ç ”ç©¶æœºåˆ¶"æ˜¯å¦å®Œæ•´ä¿ç•™ï¼‰ã€‚
            * å¼•æ–‡ä¸­çš„å› æœå…³ç³»æ˜¯å¦è¢«æ›²è§£ï¼ˆå¦‚"æ”¶å…¥æå‡å› æ•°å­—æŠ€æœ¯"â‰ "å› æ”¿ç­–æ‰¶æŒ"ï¼‰ã€‚
            * å¼•æ–‡ä¸­çš„å¦å®šè¡¨è¿°æ˜¯å¦è¢«é”™è¯¯è½¬æ¢ä¸ºè‚¯å®šï¼ˆå¦‚"æœªè¯æ˜æœ‰æ•ˆ"â‰ "è¯æ˜æœ‰æ•ˆ"ï¼‰ã€‚
        (4) å¼•ç”¨è§„èŒƒæ€§
            * å¼•ç”¨çš„æ–‡çŒ®/æœŸåˆŠæ˜¯å¦å­˜åœ¨ä¸”æœªè¢«è™šæ„ï¼ˆå¦‚DOIéªŒè¯å¤±è´¥æˆ–æœŸåˆŠå·²åœåˆŠï¼‰ã€‚
            * å¼•ç”¨ä½ç½®æ˜¯å¦å‡†ç¡®ï¼ˆå¦‚å¼•æ–‡æè¿°"ç»†èƒç–—æ³•"ï¼ŒAIè¯¯æ ‡ä¸º"åŸºå› æ²»ç–—"ï¼‰ã€‚
            * å¼•ç”¨æ ¼å¼æ˜¯å¦å®Œæ•´ï¼ˆç¼ºå¤±ä½œè€…ã€å‡ºç‰ˆå¹´ä»½ã€é¡µç ç­‰å…³é”®ä¿¡æ¯ï¼‰ã€‚
        (5) é€»è¾‘è¿è´¯æ€§
            * å¤šä¸ªå¼•æ–‡åˆå¹¶æ—¶æ˜¯å¦äº§ç”ŸçŸ›ç›¾ï¼ˆå¦‚citation:1ä¸citation:6ç»“è®ºå†²çªï¼‰ã€‚
            * å›¾è¡¨æ•°æ®ä¸æ­£æ–‡åˆ†ææ˜¯å¦ä¸€è‡´ï¼ˆå¦‚æ­£æ–‡ç§°"å…¨å›½æ•°æ®"ï¼Œå›¾è¡¨ä»…å«å±€éƒ¨æ ·æœ¬ï¼‰ã€‚
            * æ˜¯å¦å‡ºç°åå¸¸è¯†æ¨è®ºï¼ˆå¦‚"é‡å­è®¡ç®—å¯æ²»æ„ˆç™Œç—‡"æ— ä¾æ®ï¼‰ã€‚
3.  **è¾“å‡ºæ ¼å¼**ï¼š
    - è¯·ä¸è¦è¾“å‡ºæ•´ä½“çš„åˆ†ææŠ¥å‘Šï¼Œä¹Ÿä¸è¦åœ¨åˆ†æä¸­å¯¹â€œæ•´ä½“â€ä½œä»»ä½•åˆ†æï¼Œå°±åƒç”¨æ”¾å¤§é•œæŒ‘åˆºä¸€æ ·ã€‚
    - ä½ çš„è¾“å‡ºå¿…é¡»æ˜¯ä¸€ä¸ªJSONæ ¼å¼çš„åˆ—è¡¨ `[]`ã€‚
    - åˆ—è¡¨ä¸­çš„æ¯ä¸ªå¯¹è±¡ä»£è¡¨å¯¹ä¸€ä¸ªè§‚ç‚¹/å¥å­çš„åˆ†æï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
      ```json
      {
        "topic": "è¢«åˆ†æçš„å¥å­æˆ–è§‚ç‚¹",
        "citation_numbers": [å¼•ç”¨çš„ç¼–å·åˆ—è¡¨],
        "consistency": "ä¸€è‡´" æˆ– "ä¸ä¸€è‡´",
        "reason": "è¯¦ç»†çš„åˆ¤æ–­ç†ç”±ã€‚å¦‚æœä¸€è‡´ï¼Œè¯·è¯´æ˜è¯æ®åœ¨å“ªã€‚å¦‚æœä¸ä¸€è‡´ï¼Œè¯·æ˜ç¡®æŒ‡å‡ºæ˜¯å“ªä¸ªä¿¡æ¯ç‚¹åœ¨å¼•æ–‡ä¸­æ— æ³•æ‰¾åˆ°æˆ–å­˜åœ¨çŸ›ç›¾ã€‚"
      }
4. **ç©ºå¼•ç”¨æƒ…å†µï¼ˆç»å¯¹é‡è¦ï¼‰**ï¼š
    - **å®Œå…¨è·³è¿‡è§„åˆ™**ï¼šå¦‚æœä¸€ä¸ªå¥å­æ²¡æœ‰[citation:x]æ ‡è®°ï¼Œç»å¯¹ä¸èƒ½å‡ºç°åœ¨JSONè¾“å‡ºä¸­ï¼Œè¿æåŠéƒ½ä¸è¡Œ
    - **é”™è¯¯åšæ³•1**ï¼ˆç»å¯¹ç¦æ­¢ï¼‰ï¼š
      ```json
      {
        "topic": "ç«ç„°å±±çš„æœ€ä½³æ¸¸è§ˆæ—¶é—´æ˜¯æ¸…æ™¨7:00-9:00...",
        "citation_numbers": [],
        "consistency": "ä¸€è‡´",
        "reason": "è¯¥å¥æ— å¼•ç”¨æ ‡è®°ï¼Œæ ¹æ®è§„åˆ™åº”è·³è¿‡..."
      }
      ```
    - **é”™è¯¯åšæ³•2**ï¼ˆç»å¯¹ç¦æ­¢ï¼‰ï¼š
      ```json
      {
        "topic": "ä¼˜åŒ–æ“ä½œè®¾ç½®æ˜¯æå‡æ¸¸æˆä½“éªŒçš„å…³é”®ã€‚",
        "citation_numbers": [],
        "consistency": "ä¸ä¸€è‡´", 
        "reason": "è¯¥å¥æ— å¼•ç”¨æ ‡è®°..."
      }
      ```
    - **æ­£ç¡®åšæ³•**ï¼šè¿™äº›å¥å­åœ¨è¾“å‡ºJSONä¸­å®Œå…¨ä¸å­˜åœ¨ï¼Œå°±åƒå®ƒä»¬ä»æœªå‡ºç°è¿‡ä¸€æ ·

**å…³é”®ç¤ºä¾‹ï¼ˆå¼•ç”¨è¾¹ç•Œè¯†åˆ«ï¼‰**ï¼š
é”™è¯¯çš„æ–‡æœ¬ï¼š"æ ¹æ®[citation:6][citation:7][citation:8]ï¼Œåé²ç•ªçš„æœ€ä½³æ—…æ¸¸æ—¶é—´æ˜¯4-5æœˆå’Œ9-10æœˆï¼Œæ°”æ¸©é€‚å®œã€‚ç«ç„°å±±çš„æœ€ä½³æ¸¸è§ˆæ—¶é—´æ˜¯æ¸…æ™¨7:00-9:00æˆ–å‚æ™š18:00-20:00ï¼Œé¿å¼€æ­£åˆé«˜æ¸©ã€‚"

**æ­£ç¡®åˆ†ææ–¹æ³•**ï¼š
1. ç¬¬ä¸€å¥ï¼š"æ ¹æ®[citation:6][citation:7][citation:8]ï¼Œåé²ç•ªçš„æœ€ä½³æ—…æ¸¸æ—¶é—´æ˜¯4-5æœˆå’Œ9-10æœˆï¼Œæ°”æ¸©é€‚å®œã€‚" â†’ **åŒ…å«å¼•ç”¨æ ‡è®°ï¼Œéœ€è¦åˆ†æ**
2. ç¬¬äºŒå¥ï¼š"ç«ç„°å±±çš„æœ€ä½³æ¸¸è§ˆæ—¶é—´æ˜¯æ¸…æ™¨7:00-9:00æˆ–å‚æ™š18:00-20:00ï¼Œé¿å¼€æ­£åˆé«˜æ¸©ã€‚" â†’ **æ²¡æœ‰å¼•ç”¨æ ‡è®°ï¼Œå¿…é¡»è·³è¿‡**

**é”™è¯¯åšæ³•**ï¼ˆç»å¯¹ç¦æ­¢ï¼‰ï¼šå°†ç¬¬äºŒå¥ä¹Ÿå…³è”åˆ°[citation:6][citation:7][citation:8]ï¼Œè¿™æ˜¯é”™è¯¯çš„è·¨å¥å…³è”ã€‚

**ç¤ºä¾‹è¾“å‡º**ï¼š
      ```json
      [
        {
          "topic": "æ ¹æ®[citation:6][citation:7][citation:8]ï¼Œåé²ç•ªçš„æœ€ä½³æ—…æ¸¸æ—¶é—´æ˜¯4-5æœˆå’Œ9-10æœˆï¼Œæ°”æ¸©é€‚å®œ",
          "citation_numbers": [6, 7, 8],
          "consistency": "ä¸€è‡´",
          "reason": "å¼•æ–‡6ã€7ã€8å‡æ”¯æŒè¯¥æ—¶é—´æ®µå’Œæ°”æ¸©æè¿°"
        }
      ]
      ```

æ³¨æ„ï¼šä¸Šä¾‹ä¸­"ç«ç„°å±±..."å¥å­å®Œå…¨ä¸å‡ºç°åœ¨è¾“å‡ºä¸­ï¼Œå› ä¸ºå®ƒæ²¡æœ‰å¼•ç”¨æ ‡è®°ã€‚
'''

        return prompt_start + citations_text + analysis_requirements

    async def _call_alibaba_api(self, session: aiohttp.ClientSession, prompt: str, max_retries: int = 3) -> Dict[str, Any]:
        """å¼‚æ­¥è°ƒç”¨é˜¿é‡Œäº‘ç™¾ç‚¼API"""
        if not self.api_key:
            return {
                'success': False,
                'error': 'ç¼ºå°‘APIå¯†é’¥',
                'content': None
            }

        headers = {
            'Content-Type': 'application/json',
            'Authorization': f'Bearer {self.api_key}'
        }

        data = {
            'model': self.model,
            'input': {
                'messages': [
                    {
                        'role': 'user',
                        'content': prompt
                    }
                ]
            },
            'parameters': {
                'temperature': 0.2,
                'max_tokens': 15000
            }
        }

        # é‡è¯•å¾ªç¯
        last_error = None
        for attempt in range(max_retries):
            try:
                timeout = aiohttp.ClientTimeout(total=180)
                async with session.post(self.api_ep, headers=headers, json=data, timeout=timeout) as response:
                    if response.status == 200:
                        result = await response.json()
                        if result.get('output') and result['output'].get('text'):
                            return {
                                'success': True,
                                'error': None,
                                'content': result['output']['text']
                            }
                        else:
                            last_error = f'APIè¿”å›æ ¼å¼å¼‚å¸¸: {result}'
                            break

                    elif response.status == 429:
                        last_error = 'APIè°ƒç”¨é¢‘ç‡è¶…é™'
                        if attempt < max_retries - 1:
                            await asyncio.sleep(30)
                            continue

                    elif response.status >= 500:
                        response_text = await response.text()
                        last_error = f'æœåŠ¡å™¨é”™è¯¯: {response.status} - {response_text[:200]}'
                        if attempt < max_retries - 1:
                            await asyncio.sleep(10)
                            continue

                    elif response.status in [401, 403]:
                        response_text = await response.text()
                        return {
                            'success': False,
                            'error': f'è®¤è¯é”™è¯¯: {response.status} - {response_text[:200]}',
                            'content': None
                        }

                    else:
                        response_text = await response.text()
                        last_error = f'å®¢æˆ·ç«¯é”™è¯¯: {response.status} - {response_text[:200]}'
                        break

            except asyncio.TimeoutError:
                last_error = 'ç½‘ç»œè¶…æ—¶(180ç§’)'
                if attempt < max_retries - 1:
                    await asyncio.sleep(15)
                    continue

            except Exception as e:
                last_error = f'æœªçŸ¥é”™è¯¯: {str(e)}'
                if attempt < max_retries - 1:
                    await asyncio.sleep(5)
                    continue

        return {
            'success': False,
            'error': last_error or 'APIè°ƒç”¨å¤±è´¥',
            'content': None
        }

    async def _call_openai_api(self, session: aiohttp.ClientSession, prompt: str, max_retries: int = 3) -> Dict[str, Any]:
        """å¼‚æ­¥è°ƒç”¨OpenAIå…¼å®¹çš„APIï¼ˆåŒ…æ‹¬OpenAIã€DeepSeekã€NuwaAPIï¼‰"""
        if not self.api_key:
            return {
                'success': False,
                'error': 'ç¼ºå°‘APIå¯†é’¥',
                'content': None
            }

        headers = {
            'Content-Type': 'application/json',
            'Authorization': f'Bearer {self.api_key}'
        }

        data = {
            'model': self.model,
            'messages': [
                {
                    'role': 'user',
                    'content': prompt
                }
            ],
            'temperature': 0.2,
            'max_tokens': 15000
        }

        # é‡è¯•å¾ªç¯
        last_error = None
        for attempt in range(max_retries):
            try:
                timeout = aiohttp.ClientTimeout(total=180)
                async with session.post(self.api_ep, headers=headers, json=data, timeout=timeout) as response:
                    if response.status == 200:
                        result = await response.json()
                        if result.get('choices') and len(result['choices']) > 0:
                            return {
                                'success': True,
                                'error': None,
                                'content': result['choices'][0]['message']['content']
                            }
                        else:
                            last_error = f'APIè¿”å›æ ¼å¼å¼‚å¸¸: {result}'
                            break

                    elif response.status == 429:
                        last_error = 'APIè°ƒç”¨é¢‘ç‡è¶…é™'
                        if attempt < max_retries - 1:
                            await asyncio.sleep(30)
                            continue

                    elif response.status >= 500:
                        response_text = await response.text()
                        last_error = f'æœåŠ¡å™¨é”™è¯¯: {response.status} - {response_text[:200]}'
                        if attempt < max_retries - 1:
                            await asyncio.sleep(10)
                            continue

                    elif response.status in [401, 403]:
                        response_text = await response.text()
                        return {
                            'success': False,
                            'error': f'è®¤è¯é”™è¯¯: {response.status} - {response_text[:200]}',
                            'content': None
                        }

                    else:
                        response_text = await response.text()
                        last_error = f'å®¢æˆ·ç«¯é”™è¯¯: {response.status} - {response_text[:200]}'
                        break

            except asyncio.TimeoutError:
                last_error = 'ç½‘ç»œè¶…æ—¶(180ç§’)'
                if attempt < max_retries - 1:
                    await asyncio.sleep(15)
                    continue

            except Exception as e:
                last_error = f'æœªçŸ¥é”™è¯¯: {str(e)}'
                if attempt < max_retries - 1:
                    await asyncio.sleep(5)
                    continue

        return {
            'success': False,
            'error': last_error or 'APIè°ƒç”¨å¤±è´¥',
            'content': None
        }

    async def call_api_async(self, session: aiohttp.ClientSession, prompt: str, max_retries: int = 3) -> Dict[str, Any]:
        """å¼‚æ­¥è°ƒç”¨APIï¼ˆæ”¯æŒå¤šæä¾›å•†ï¼‰"""
        return await self.api_client.call_async(session, prompt, max_retries=max_retries)

    def _call_alibaba_api_sync(self, prompt: str, max_retries: int = 3) -> Dict[str, Any]:
        """åŒæ­¥è°ƒç”¨é˜¿é‡Œäº‘ç™¾ç‚¼API"""
        if not self.api_key:
            return {
                'success': False,
                'error': 'ç¼ºå°‘APIå¯†é’¥',
                'content': None
            }

        headers = {
            'Content-Type': 'application/json',
            'Authorization': f'Bearer {self.api_key}'
        }

        data = {
            'model': self.model,
            'input': {
                'messages': [
                    {
                        'role': 'user',
                        'content': prompt
                    }
                ]
            },
            'parameters': {
                'temperature': 0.2,
                'max_tokens': 15000
            }
        }

        prompt_tokens = self.count_chars(prompt)
        print(f"    è°ƒç”¨é˜¿é‡Œäº‘API... (ä¼°ç®—è¯·æ±‚Token: {prompt_tokens})")

        # é‡è¯•å¾ªç¯
        last_error = None
        for attempt in range(max_retries):
            try:
                if attempt > 0:
                    print(f"    ç¬¬{attempt + 1}æ¬¡é‡è¯•...")

                response = requests.post(self.api_ep, headers=headers, json=data, timeout=180)

                if response.status_code == 200:
                    result = response.json()
                    print(f"    APIè°ƒç”¨æˆåŠŸ (ç¬¬{attempt + 1}æ¬¡å°è¯•)")

                    if result.get('output') and result['output'].get('text'):
                        content = result['output']['text']
                        response_tokens = self.count_chars(content)
                        print(f"    ä¼°ç®—å“åº”Token: {response_tokens}")
                        return {
                            'success': True,
                            'error': None,
                            'content': content
                        }
                    else:
                        print(f"    APIè¿”å›æ ¼å¼å¼‚å¸¸: {result}")
                        last_error = f'APIè¿”å›æ ¼å¼å¼‚å¸¸: {result}'
                        break

                elif response.status_code == 429:
                    print(f"    APIè°ƒç”¨é¢‘ç‡è¶…é™ (ç¬¬{attempt + 1}æ¬¡å°è¯•)ï¼Œç­‰å¾…30ç§’åé‡è¯•")
                    last_error = 'APIè°ƒç”¨é¢‘ç‡è¶…é™'
                    if attempt < max_retries - 1:
                        time.sleep(30)
                        continue

                elif response.status_code >= 500:
                    print(f"    æœåŠ¡å™¨é”™è¯¯ {response.status_code} (ç¬¬{attempt + 1}æ¬¡å°è¯•)ï¼Œç­‰å¾…10ç§’åé‡è¯•")
                    last_error = f'æœåŠ¡å™¨é”™è¯¯: {response.status_code} - {response.text[:200]}'
                    if attempt < max_retries - 1:
                        time.sleep(10)
                        continue

                elif response.status_code in [401, 403]:
                    print(f"    è®¤è¯é”™è¯¯ {response.status_code}ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥")
                    return {
                        'success': False,
                        'error': f'è®¤è¯é”™è¯¯: {response.status_code} - {response.text[:200]}',
                        'content': None
                    }

                else:
                    print(f"    å®¢æˆ·ç«¯é”™è¯¯ {response.status_code}")
                    last_error = f'å®¢æˆ·ç«¯é”™è¯¯: {response.status_code} - {response.text[:200]}'
                    break

            except requests.exceptions.Timeout:
                print(f"    ç½‘ç»œè¶…æ—¶ (ç¬¬{attempt + 1}æ¬¡å°è¯•ï¼Œ180ç§’)")
                last_error = 'ç½‘ç»œè¶…æ—¶(180ç§’)'
                if attempt < max_retries - 1:
                    print(f"    ç­‰å¾…15ç§’åè¿›è¡Œç¬¬{attempt + 2}æ¬¡å°è¯•")
                    time.sleep(15)
                    continue

            except requests.exceptions.ConnectionError:
                print(f"    ç½‘ç»œè¿æ¥å¤±è´¥ (ç¬¬{attempt + 1}æ¬¡å°è¯•)")
                last_error = 'ç½‘ç»œè¿æ¥å¤±è´¥'
                if attempt < max_retries - 1:
                    print(f"    ç­‰å¾…10ç§’åè¿›è¡Œç¬¬{attempt + 2}æ¬¡å°è¯•")
                    time.sleep(10)
                    continue

            except Exception as e:
                print(f"    æœªçŸ¥é”™è¯¯ (ç¬¬{attempt + 1}æ¬¡å°è¯•): {str(e)}")
                last_error = f'æœªçŸ¥é”™è¯¯: {str(e)}'
                if attempt < max_retries - 1:
                    print(f"    ç­‰å¾…5ç§’åè¿›è¡Œç¬¬{attempt + 2}æ¬¡å°è¯•")
                    time.sleep(5)
                    continue

        print(f"    APIè°ƒç”¨æœ€ç»ˆå¤±è´¥ï¼Œå·²é‡è¯•{max_retries}æ¬¡")
        return {
            'success': False,
            'error': last_error or 'APIè°ƒç”¨å¤±è´¥',
            'content': None
        }

    def _call_openai_api_sync(self, prompt: str, max_retries: int = 3) -> Dict[str, Any]:
        """åŒæ­¥è°ƒç”¨OpenAIå…¼å®¹çš„APIï¼ˆåŒ…æ‹¬OpenAIã€DeepSeekã€NuwaAPIï¼‰"""
        if not self.api_key:
            return {
                'success': False,
                'error': 'ç¼ºå°‘APIå¯†é’¥',
                'content': None
            }

        headers = {
            'Content-Type': 'application/json',
            'Authorization': f'Bearer {self.api_key}'
        }

        data = {
            'model': self.model,
            'messages': [
                {
                    'role': 'user',
                    'content': prompt
                }
            ],
            'temperature': 0.2,
            'max_tokens': 15000
        }

        prompt_tokens = self.count_chars(prompt)
        print(f"    è°ƒç”¨{self.provider}API... (ä¼°ç®—è¯·æ±‚Token: {prompt_tokens})")

        # é‡è¯•å¾ªç¯
        last_error = None
        for attempt in range(max_retries):
            try:
                if attempt > 0:
                    print(f"    ç¬¬{attempt + 1}æ¬¡é‡è¯•...")

                response = requests.post(self.api_ep, headers=headers, json=data, timeout=180)

                if response.status_code == 200:
                    result = response.json()
                    print(f"    APIè°ƒç”¨æˆåŠŸ (ç¬¬{attempt + 1}æ¬¡å°è¯•)")

                    if result.get('choices') and len(result['choices']) > 0:
                        content = result['choices'][0]['message']['content']
                        response_tokens = self.count_chars(content)
                        print(f"    ä¼°ç®—å“åº”Token: {response_tokens}")
                        return {
                            'success': True,
                            'error': None,
                            'content': content
                        }
                    else:
                        print(f"    APIè¿”å›æ ¼å¼å¼‚å¸¸: {result}")
                        last_error = f'APIè¿”å›æ ¼å¼å¼‚å¸¸: {result}'
                        break

                elif response.status_code == 429:
                    print(f"    APIè°ƒç”¨é¢‘ç‡è¶…é™ (ç¬¬{attempt + 1}æ¬¡å°è¯•)ï¼Œç­‰å¾…30ç§’åé‡è¯•")
                    last_error = 'APIè°ƒç”¨é¢‘ç‡è¶…é™'
                    if attempt < max_retries - 1:
                        time.sleep(30)
                        continue

                elif response.status_code >= 500:
                    print(f"    æœåŠ¡å™¨é”™è¯¯ {response.status_code} (ç¬¬{attempt + 1}æ¬¡å°è¯•)ï¼Œç­‰å¾…10ç§’åé‡è¯•")
                    last_error = f'æœåŠ¡å™¨é”™è¯¯: {response.status_code} - {response.text[:200]}'
                    if attempt < max_retries - 1:
                        time.sleep(10)
                        continue

                elif response.status_code in [401, 403]:
                    print(f"    è®¤è¯é”™è¯¯ {response.status_code}ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥")
                    return {
                        'success': False,
                        'error': f'è®¤è¯é”™è¯¯: {response.status_code} - {response.text[:200]}',
                        'content': None
                    }

                else:
                    print(f"    å®¢æˆ·ç«¯é”™è¯¯ {response.status_code}")
                    last_error = f'å®¢æˆ·ç«¯é”™è¯¯: {response.status_code} - {response.text[:200]}'
                    break

            except requests.exceptions.Timeout:
                print(f"    ç½‘ç»œè¶…æ—¶ (ç¬¬{attempt + 1}æ¬¡å°è¯•ï¼Œ180ç§’)")
                last_error = 'ç½‘ç»œè¶…æ—¶(180ç§’)'
                if attempt < max_retries - 1:
                    print(f"    ç­‰å¾…15ç§’åè¿›è¡Œç¬¬{attempt + 2}æ¬¡å°è¯•")
                    time.sleep(15)
                    continue

            except requests.exceptions.ConnectionError:
                print(f"    ç½‘ç»œè¿æ¥å¤±è´¥ (ç¬¬{attempt + 1}æ¬¡å°è¯•)")
                last_error = 'ç½‘ç»œè¿æ¥å¤±è´¥'
                if attempt < max_retries - 1:
                    print(f"    ç­‰å¾…10ç§’åè¿›è¡Œç¬¬{attempt + 2}æ¬¡å°è¯•")
                    time.sleep(10)
                    continue

            except Exception as e:
                print(f"    æœªçŸ¥é”™è¯¯ (ç¬¬{attempt + 1}æ¬¡å°è¯•): {str(e)}")
                last_error = f'æœªçŸ¥é”™è¯¯: {str(e)}'
                if attempt < max_retries - 1:
                    print(f"    ç­‰å¾…5ç§’åè¿›è¡Œç¬¬{attempt + 2}æ¬¡å°è¯•")
                    time.sleep(5)
                    continue

        print(f"    APIè°ƒç”¨æœ€ç»ˆå¤±è´¥ï¼Œå·²é‡è¯•{max_retries}æ¬¡")
        return {
            'success': False,
            'error': last_error or 'APIè°ƒç”¨å¤±è´¥',
            'content': None
        }

    def call_api(self, prompt: str, max_retries: int = 3) -> Dict[str, Any]:
        """åŒæ­¥è°ƒç”¨APIï¼ˆæ”¯æŒå¤šæä¾›å•†ï¼‰"""
        return self.api_client.call_sync(prompt, max_retries=max_retries)

    def analyze_citation_quality(self, row: pd.Series) -> Dict[str, Any]:
        """åˆ†æå•è¡Œæ•°æ®çš„å¼•ç”¨è´¨é‡"""
        question = str(row['æ¨¡å‹prompt'])
        answer = str(row['ç­”æ¡ˆ'])

        # æ„å»ºå¼•æ–‡å­—å…¸
        citations_dict = {}
        for i in range(1, 21):
            col_name = f'å¼•æ–‡{i}'
            if col_name in row and pd.notna(row[col_name]):
                citations_dict[i] = str(row[col_name])

        # æå–ä½¿ç”¨çš„å¼•ç”¨
        citations_used = self.extract_citations(answer)

        print(f"    é—®é¢˜é•¿åº¦: {len(question)}å­—ç¬¦")
        print(f"    ç­”æ¡ˆé•¿åº¦: {len(answer)}å­—ç¬¦")
        print(f"    å¯ç”¨å¼•æ–‡: {len(citations_dict)}ä¸ª")
        print(f"    å®é™…å¼•ç”¨: {citations_used}")

        # å¦‚æœæ²¡æœ‰ä»»ä½•å¼•ç”¨ï¼Œè·³è¿‡åˆ†æ
        if not citations_used:
            print("    è·³è¿‡åˆ†æï¼šç­”æ¡ˆä¸­æ²¡æœ‰ä»»ä½•å¼•ç”¨æ ‡è®°")
            return {
                'question': question,
                'answer_preview': answer[:200] + '...' if len(answer) > 200 else answer,
                'citations_used': citations_used,
                'citations_available': list(citations_dict.keys()),
                'api_success': True,  # æ ‡è®°ä¸ºæˆåŠŸä½†è·³è¿‡
                'api_error': None,
                'analysis': 'è·³è¿‡åˆ†æï¼šç­”æ¡ˆä¸­æ²¡æœ‰å¼•ç”¨æ ‡è®°',
                'skipped': True
            }

        # ç”Ÿæˆåˆ†æprompt
        analysis_prompt = self.prepare_analysis_prompt(question, answer, citations_dict)

        # è°ƒç”¨APIåˆ†æ
        api_result = self.call_api(analysis_prompt)

        analysis_content = None
        if api_result['success']:
            try:
                # å°è¯•è§£æAPIè¿”å›çš„JSONå­—ç¬¦ä¸²
                analysis_content = json.loads(api_result['content'])
            except json.JSONDecodeError:
                # å¦‚æœè§£æå¤±è´¥ï¼Œè¯´æ˜è¿”å›çš„ä¸æ˜¯åˆæ³•çš„JSONï¼Œä½œä¸ºåŸå§‹æ–‡æœ¬å¤„ç†
                analysis_content = api_result['content']

        result = {
            'question': question,
            'answer_preview': answer[:200] + '...' if len(answer) > 200 else answer,
            'citations_used': citations_used,
            'citations_available': list(citations_dict.keys()),
            'api_success': api_result['success'],
            'api_error': api_result['error'],
            'analysis': analysis_content,
            'skipped': False
        }

        return result

    async def analyze_citation_quality_async(self, session: aiohttp.ClientSession, row: pd.Series, rank: int) -> Dict[
        str, Any]:
        """å¼‚æ­¥åˆ†æå•è¡Œæ•°æ®çš„å¼•ç”¨è´¨é‡"""
        question = str(row['æ¨¡å‹prompt'])
        answer = str(row['ç­”æ¡ˆ'])

        # æ„å»ºå¼•æ–‡å­—å…¸
        citations_dict = {}
        for i in range(1, 21):
            col_name = f'å¼•æ–‡{i}'
            if col_name in row and pd.notna(row[col_name]):
                citations_dict[i] = str(row[col_name])

        # æå–ä½¿ç”¨çš„å¼•ç”¨
        citations_used = self.extract_citations(answer)

        # å¦‚æœæ²¡æœ‰ä»»ä½•å¼•ç”¨ï¼Œè·³è¿‡åˆ†æ
        if not citations_used:
            return {
                'rank': rank,
                'question': question,
                'answer_preview': answer[:200] + '...' if len(answer) > 200 else answer,
                'citations_used': citations_used,
                'citations_available': list(citations_dict.keys()),
                'api_success': True,  # æ ‡è®°ä¸ºæˆåŠŸä½†è·³è¿‡
                'api_error': None,
                'analysis': 'è·³è¿‡åˆ†æï¼šç­”æ¡ˆä¸­æ²¡æœ‰å¼•ç”¨æ ‡è®°',
                'skipped': True
            }

        # ç”Ÿæˆåˆ†æprompt
        analysis_prompt = self.prepare_analysis_prompt(question, answer, citations_dict)

        # è°ƒç”¨å¼‚æ­¥APIåˆ†æ
        api_result = await self.call_api_async(session, analysis_prompt)

        analysis_content = None
        if api_result['success']:
            try:
                # å°è¯•è§£æAPIè¿”å›çš„JSONå­—ç¬¦ä¸²
                analysis_content = json.loads(api_result['content'])
            except json.JSONDecodeError:
                # å¦‚æœè§£æå¤±è´¥ï¼Œè¯´æ˜è¿”å›çš„ä¸æ˜¯åˆæ³•çš„JSONï¼Œä½œä¸ºåŸå§‹æ–‡æœ¬å¤„ç†
                analysis_content = api_result['content']

        result = {
            'rank': rank,
            'question': question,
            'answer_preview': answer[:200] + '...' if len(answer) > 200 else answer,
            'citations_used': citations_used,
            'citations_available': list(citations_dict.keys()),
            'api_success': api_result['success'],
            'api_error': api_result['error'],
            'analysis': analysis_content,
            'skipped': False
        }

        return result

    async def batch_analyze_concurrent(self, excel_path: str, num_samples: int = None, specific_rank: int = None,
                                       start_from: int = None) -> List[Dict[str, Any]]:
        """å¼‚æ­¥å¹¶å‘æ‰¹é‡åˆ†æ"""
        df = self.load_data(excel_path)
        if df is None:
            return []

        # ç¡®å®šè¦å¤„ç†çš„æ•°æ®
        if specific_rank is not None:
            # å¤„ç†ç‰¹å®šrankçš„å•æ¡æ•°æ®
            if specific_rank <= 0 or specific_rank > len(df):
                print(f"é”™è¯¯ï¼šæŒ‡å®šçš„rank {specific_rank} è¶…å‡ºæ•°æ®èŒƒå›´ (1-{len(df)})")
                return []
            sample_df = df.iloc[[specific_rank - 1]]  # rankæ˜¯1-basedï¼Œè½¬ä¸º0-basedç´¢å¼•
            total_count = 1
            print(f"å¼€å§‹åˆ†æç¬¬{specific_rank}æ¡æ•°æ®...")
        elif start_from is not None:
            # ä»æŒ‡å®šä½ç½®å¼€å§‹å¤„ç†æŒ‡å®šæ•°é‡çš„æ•°æ®
            if start_from <= 0 or start_from > len(df):
                print(f"é”™è¯¯ï¼šèµ·å§‹ä½ç½® {start_from} è¶…å‡ºæ•°æ®èŒƒå›´ (1-{len(df)})")
                return []
            start_idx = start_from - 1  # start_fromæ˜¯1-basedï¼Œè½¬ä¸º0-basedç´¢å¼•
            if num_samples is None:
                # ä»èµ·å§‹ä½ç½®åˆ°ç»“å°¾
                sample_df = df.iloc[start_idx:]
                total_count = len(df) - start_idx
                print(f"å¼€å§‹åˆ†æä»ç¬¬{start_from}æ¡å¼€å§‹çš„æ‰€æœ‰æ•°æ®ï¼ˆå…±{total_count}æ¡ï¼‰...")
            else:
                # ä»èµ·å§‹ä½ç½®å¼€å§‹æŒ‡å®šæ•°é‡
                end_idx = min(start_idx + num_samples, len(df))
                sample_df = df.iloc[start_idx:end_idx]
                total_count = len(sample_df)
                print(f"å¼€å§‹åˆ†æä»ç¬¬{start_from}æ¡å¼€å§‹çš„{total_count}æ¡æ•°æ®...")
        elif num_samples is None:
            # å¤„ç†æ‰€æœ‰æ•°æ®
            sample_df = df
            total_count = len(df)
            print(f"å¼€å§‹å¹¶å‘åˆ†ææ‰€æœ‰{total_count}æ¡å®Œæ•´é—®ç­”æ•°æ®...")
        else:
            # å¤„ç†å‰num_samplesæ¡æ•°æ®
            sample_df = df.head(num_samples)
            total_count = num_samples
            print(f"å¼€å§‹å¹¶å‘åˆ†æå‰{num_samples}æ¡å®Œæ•´é—®ç­”æ•°æ®...")

        print(f"ä½¿ç”¨ç™¾ç‚¼APIï¼Œå¹¶å‘é™åˆ¶: {self.concurrent_limit}æ¡")

        # åˆ›å»ºä¿¡å·é‡æ¥æ§åˆ¶å¹¶å‘æ•°é‡
        semaphore = asyncio.Semaphore(self.concurrent_limit)

        async def process_with_semaphore(session, row, rank):
            async with semaphore:
                result = await self.analyze_citation_quality_async(session, row, rank + 1)
                return result

        # åˆ›å»ºHTTPä¼šè¯
        connector = aiohttp.TCPConnector(limit=100)  # è¿æ¥æ± å¤§å°
        async with aiohttp.ClientSession(connector=connector) as session:
            # åˆ›å»ºä»»åŠ¡åˆ—è¡¨
            tasks = []
            for idx, row in sample_df.iterrows():
                task = process_with_semaphore(session, row, idx)
                tasks.append(task)

            # æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡å¹¶æ˜¾ç¤ºè¿›åº¦
            print(f"å¼€å§‹å¤„ç†{len(tasks)}ä¸ªä»»åŠ¡...")
            start_time = time.time()

            completed_tasks = []
            for task in asyncio.as_completed(tasks):
                result = await task
                completed_tasks.append(result)

                # æ˜¾ç¤ºè¿›åº¦
                progress = len(completed_tasks)
                elapsed = time.time() - start_time
                avg_time = elapsed / progress if progress > 0 else 0
                eta = avg_time * (total_count - progress)

                status = "âœ“" if result['api_success'] else "âœ—"
                print(f"[{progress}/{total_count}] {status} ç¬¬{result['rank']}æ¡ "
                      f"(ç”¨æ—¶: {elapsed:.1f}s, ETA: {eta:.1f}s)")

        # æŒ‰rankæ’åºç»“æœ
        completed_tasks.sort(key=lambda x: x['rank'])

        # ç»Ÿè®¡ç»“æœ
        success_count = sum(1 for r in completed_tasks if r['api_success'])
        failed_count = len(completed_tasks) - success_count

        total_time = time.time() - start_time
        print(f"\n=== å¹¶å‘åˆ†æå®Œæˆ ===")
        print(f"æ€»ç”¨æ—¶: {total_time:.1f}ç§’")
        print(f"å¹³å‡æ¯æ¡: {total_time / len(completed_tasks):.2f}ç§’")
        print(f"æˆåŠŸ: {success_count}æ¡, å¤±è´¥: {failed_count}æ¡")

        return completed_tasks

    def batch_analyze(self, excel_path: str, num_samples: int = 10, specific_rank: int = None, start_from: int = None) -> \
    List[Dict[str, Any]]:
        """æ‰¹é‡åˆ†ææ•°æ®ï¼Œnum_samples=Noneæ—¶å¤„ç†æ‰€æœ‰æ•°æ®"""
        df = self.load_data(excel_path)
        if df is None:
            return []

        # ç¡®å®šè¦å¤„ç†çš„æ•°æ®
        if specific_rank is not None:
            # å¤„ç†ç‰¹å®šrankçš„å•æ¡æ•°æ®
            if specific_rank <= 0 or specific_rank > len(df):
                print(f"é”™è¯¯ï¼šæŒ‡å®šçš„rank {specific_rank} è¶…å‡ºæ•°æ®èŒƒå›´ (1-{len(df)})")
                return []
            sample_df = df.iloc[[specific_rank - 1]]  # rankæ˜¯1-basedï¼Œè½¬ä¸º0-basedç´¢å¼•
            total_count = 1
            print(f"å¼€å§‹åˆ†æç¬¬{specific_rank}æ¡æ•°æ®...")
        elif start_from is not None:
            # ä»æŒ‡å®šä½ç½®å¼€å§‹å¤„ç†æŒ‡å®šæ•°é‡çš„æ•°æ®
            if start_from <= 0 or start_from > len(df):
                print(f"é”™è¯¯ï¼šèµ·å§‹ä½ç½® {start_from} è¶…å‡ºæ•°æ®èŒƒå›´ (1-{len(df)})")
                return []
            start_idx = start_from - 1  # start_fromæ˜¯1-basedï¼Œè½¬ä¸º0-basedç´¢å¼•
            if num_samples is None:
                # ä»èµ·å§‹ä½ç½®åˆ°ç»“å°¾
                sample_df = df.iloc[start_idx:]
                total_count = len(df) - start_idx
                print(f"å¼€å§‹åˆ†æä»ç¬¬{start_from}æ¡å¼€å§‹çš„æ‰€æœ‰æ•°æ®ï¼ˆå…±{total_count}æ¡ï¼‰...")
            else:
                # ä»èµ·å§‹ä½ç½®å¼€å§‹æŒ‡å®šæ•°é‡
                end_idx = min(start_idx + num_samples, len(df))
                sample_df = df.iloc[start_idx:end_idx]
                total_count = len(sample_df)
                print(f"å¼€å§‹åˆ†æä»ç¬¬{start_from}æ¡å¼€å§‹çš„{total_count}æ¡æ•°æ®...")
        elif num_samples is None:
            # å¤„ç†æ‰€æœ‰æ•°æ®
            sample_df = df
            total_count = len(df)
            print(f"å¼€å§‹åˆ†ææ‰€æœ‰{total_count}æ¡å®Œæ•´é—®ç­”æ•°æ®...")
        else:
            # å¤„ç†å‰num_samplesæ¡æ•°æ®
            sample_df = df.head(num_samples)
            total_count = num_samples
            print(f"å¼€å§‹åˆ†æå‰{num_samples}æ¡å®Œæ•´é—®ç­”æ•°æ®...")

        results = []
        success_count = 0
        failed_count = 0

        print("ä½¿ç”¨ç™¾ç‚¼APIï¼Œæ”¯æŒé‡è¯•æœºåˆ¶å’Œè¶…æ—¶å»¶é•¿")

        for idx, row in sample_df.iterrows():
            # ä½¿ç”¨åŸå§‹ç´¢å¼•+1ä½œä¸ºrank
            actual_rank = idx + 1
            print(f"\n=== æ­£åœ¨åˆ†æç¬¬{actual_rank}æ¡æ•°æ® (DataFrameç´¢å¼•: {idx}) ===")

            result = self.analyze_citation_quality(row)

            if result['api_success']:
                print("    âœ“ åˆ†ææˆåŠŸ")
                success_count += 1
            else:
                print(f"    âœ— åˆ†æå¤±è´¥: {result['api_error']}")
                failed_count += 1

            results.append({
                'rank': actual_rank,
                **result
            })

            # ç®€åŒ–è°ƒç”¨é—´éš”ï¼Œé‡è¯•æœºåˆ¶å·²ç»å¤„ç†äº†å¤§éƒ¨åˆ†é”™è¯¯æƒ…å†µ
            if result['api_success']:
                time.sleep(3)  # æˆåŠŸåç­‰3ç§’ï¼ˆåŸ5ç§’ï¼‰
            else:
                time.sleep(1)  # å¤±è´¥åç­‰1ç§’ï¼ˆåŸ2ç§’ï¼‰ï¼Œå› ä¸ºé‡è¯•æœºåˆ¶å·²ç»ç­‰å¾…è¿‡äº†

        print(f"\n=== æ–¹æ¡ˆ1ç™¾ç‚¼ç‰ˆåˆ†æå®Œæˆ ===")
        print(f"æˆåŠŸ: {success_count}æ¡, å¤±è´¥: {failed_count}æ¡")

        return results

    def save_results(self, results: List[Dict[str, Any]], output_path: str):
        """ä¿å­˜åˆ†æç»“æœï¼Œå¢å¼ºé”™è¯¯å¤„ç†"""
        try:
            # åˆ›å»ºç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            import os
            output_dir = os.path.dirname(output_path)
            if output_dir and not os.path.exists(output_dir):
                os.makedirs(output_dir)
                print(f"åˆ›å»ºè¾“å‡ºç›®å½•ï¼š{output_dir}")

            # ä¿å­˜ç»“æœ
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            print(f"âœ“ ç»“æœå·²æˆåŠŸä¿å­˜åˆ°ï¼š{output_path}")
            print(f"    æ–‡ä»¶å¤§å°ï¼š{os.path.getsize(output_path)} å­—èŠ‚")

        except PermissionError:
            print(f"âœ— ä¿å­˜å¤±è´¥ï¼šæ²¡æœ‰å†™å…¥æƒé™ - {output_path}")
        except FileNotFoundError:
            print(f"âœ— ä¿å­˜å¤±è´¥ï¼šè·¯å¾„ä¸å­˜åœ¨ - {output_path}")
        except Exception as e:
            print(f"âœ— ä¿å­˜å¤±è´¥ï¼š{e}")


def get_user_choice() -> dict:
    """è·å–ç”¨æˆ·é€‰æ‹©çš„è¿è¡Œæ¨¡å¼"""
    print("\n=== å¼•æ–‡åˆ†æè„šæœ¬ ===")
    print("è¯·é€‰æ‹©è¿è¡Œæ¨¡å¼ï¼š")
    print("1. åˆ†æç‰¹å®šrankçš„å•æ¡æ•°æ®ï¼ˆåŒæ­¥æ¨¡å¼ï¼‰")
    print("2. ä»æŒ‡å®šä½ç½®å¼€å§‹åˆ†ææŒ‡å®šæ•°é‡çš„æ•°æ®ï¼ˆåŒæ­¥æ¨¡å¼ï¼‰")
    print("3. åˆ†ææ‰€æœ‰æ•°æ®ï¼ˆå¹¶å‘æ¨¡å¼ï¼‰")
    print("4. åˆ†æå‰Næ¡æ•°æ®ï¼ˆå¹¶å‘æ¨¡å¼ï¼‰")
    print("5. ä»æŒ‡å®šä½ç½®å¼€å§‹åˆ†ææŒ‡å®šæ•°é‡çš„æ•°æ®ï¼ˆå¹¶å‘æ¨¡å¼ï¼‰")
    print("6. é€€å‡º")

    while True:
        try:
            choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1-6): ").strip()

            if choice == '1':
                rank = int(input("è¯·è¾“å…¥è¦åˆ†æçš„rank (ä»1å¼€å§‹): "))
                return {"mode": "specific_rank", "specific_rank": rank}

            elif choice == '2':
                start_from = int(input("è¯·è¾“å…¥èµ·å§‹ä½ç½® (ä»1å¼€å§‹): "))
                count_input = input("è¯·è¾“å…¥è¦åˆ†æçš„æ•°é‡ (ç•™ç©ºè¡¨ç¤ºåˆ†æåˆ°ç»“å°¾): ").strip()
                num_samples = int(count_input) if count_input else None
                return {"mode": "start_from", "start_from": start_from, "num_samples": num_samples}

            elif choice == '3':
                return {"mode": "all", "num_samples": None}

            elif choice == '4':
                num_samples = int(input("è¯·è¾“å…¥è¦åˆ†æçš„æ•°æ®é‡: "))
                return {"mode": "head", "num_samples": num_samples}

            elif choice == '5':
                start_from = int(input("è¯·è¾“å…¥èµ·å§‹ä½ç½® (ä»1å¼€å§‹): "))
                count_input = input("è¯·è¾“å…¥è¦åˆ†æçš„æ•°é‡ (ç•™ç©ºè¡¨ç¤ºåˆ†æåˆ°ç»“å°¾): ").strip()
                num_samples = int(count_input) if count_input else None
                return {"mode": "start_from_async", "start_from": start_from, "num_samples": num_samples}

            elif choice == '6':
                print("é€€å‡ºç¨‹åº")
                return {"mode": "exit"}

            else:
                print("æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")

        except ValueError:
            print("è¾“å…¥æ ¼å¼é”™è¯¯ï¼Œè¯·è¾“å…¥æ•°å­—")
        except KeyboardInterrupt:
            print("\nç”¨æˆ·å–æ¶ˆæ“ä½œ")
            return {"mode": "exit"}


def main_unified():
    """ç»Ÿä¸€ä¸»å‡½æ•°ï¼Œæ ¹æ®ç”¨æˆ·é€‰æ‹©å†³å®šåŒæ­¥æˆ–å¼‚æ­¥"""
    # è·å–ç”¨æˆ·é€‰æ‹©
    user_choice = get_user_choice()
    if user_choice["mode"] == "exit":
        return

    # æ ¹æ®æ¨¡å¼å†³å®šä½¿ç”¨åŒæ­¥è¿˜æ˜¯å¼‚æ­¥
    if user_choice["mode"] in ["specific_rank", "start_from"]:
        # åŒæ­¥æ¨¡å¼
        main_sync(user_choice)
    else:
        # å¼‚æ­¥æ¨¡å¼
        asyncio.run(main_async_impl(user_choice))


def main_sync(user_choice):
    """åŒæ­¥ç‰ˆæœ¬ä¸»å‡½æ•°"""
    analyzer = Method1BailianAnalyzer()

    # è·å–é¡¹ç›®æ ¹ç›®å½•è·¯å¾„
    script_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(os.path.dirname(script_dir))
    
    # æ•°æ®è·¯å¾„
    excel_path = os.path.join(project_root, "data", "input", "æ­£æ–‡å¼•æ–‡å†…å®¹ï¼ˆçº¯å‡€ç‰ˆï¼‰.xlsx")
    output_dir = os.path.join(project_root, "data", "output", "results")
    os.makedirs(output_dir, exist_ok=True)

    # æ ¹æ®ç”¨æˆ·é€‰æ‹©è®¾ç½®è¾“å‡ºæ–‡ä»¶å
    if user_choice["mode"] == "specific_rank":
        output_path = os.path.join(output_dir, f"citation_analysis_rank_{user_choice['specific_rank']}_sync_results.json")
    elif user_choice["mode"] == "start_from":
        if user_choice.get("num_samples"):
            output_path = os.path.join(output_dir, f"citation_analysis_from_{user_choice['start_from']}_count_{user_choice['num_samples']}_sync_results.json")
        else:
            output_path = os.path.join(output_dir, f"citation_analysis_from_{user_choice['start_from']}_to_end_sync_results.json")
    else:
        output_path = os.path.join(output_dir, "citation_analysis_sync_results.json")

    print(f"å¼€å§‹åŒæ­¥åˆ†æ...")
    print(f"è¾“å‡ºæ–‡ä»¶ï¼š{output_path}")

    # æ ¹æ®ç”¨æˆ·é€‰æ‹©è°ƒç”¨ä¸åŒçš„åˆ†ææ–¹æ³•
    if user_choice["mode"] == "specific_rank":
        results = analyzer.batch_analyze(excel_path, specific_rank=user_choice["specific_rank"])
    elif user_choice["mode"] == "start_from":
        results = analyzer.batch_analyze(excel_path,
                                         num_samples=user_choice.get("num_samples"),
                                         start_from=user_choice["start_from"])
    else:
        results = analyzer.batch_analyze(excel_path)

    if results:
        analyzer.save_results(results, output_path)
        print(f"\næ–¹æ¡ˆ1ç™¾ç‚¼ç‰ˆåˆ†æå®Œæˆï¼")

        # æ˜¾ç¤ºæˆåŠŸçš„ç»“æœé¢„è§ˆ
        success_results = [r for r in results if r['api_success']]
        if success_results:
            print(f"\næˆåŠŸåˆ†æç¤ºä¾‹ï¼š")
            for i, result in enumerate(success_results[:1]):
                print(f"\n{i + 1}. ç¬¬{result['rank']}æ¡æ•°æ®:")
                print(f"   ä½¿ç”¨å¼•ç”¨: {result['citations_used']}")
                print(f"   å¯ç”¨å¼•æ–‡: {len(result['citations_available'])}ä¸ª")
                if result['analysis']:
                    print(f"   åˆ†æç‰‡æ®µ: {result['analysis'][:150]}...")
    else:
        print("åˆ†æå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®æ–‡ä»¶å’ŒAL_KEYé…ç½®")


async def main_async_impl(user_choice):
    """å¼‚æ­¥å¹¶å‘ç‰ˆæœ¬çš„ä¸»å‡½æ•°å®ç°"""
    analyzer = Method1BailianAnalyzer(concurrent_limit=50)  # 50å¹¶å‘

    # è·å–é¡¹ç›®æ ¹ç›®å½•è·¯å¾„
    script_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(os.path.dirname(script_dir))
    
    # æ•°æ®è·¯å¾„
    excel_path = os.path.join(project_root, "data", "input", "æ­£æ–‡å¼•æ–‡å†…å®¹ï¼ˆçº¯å‡€ç‰ˆï¼‰.xlsx")
    output_dir = os.path.join(project_root, "data", "output", "results")
    os.makedirs(output_dir, exist_ok=True)

    # æ ¹æ®ç”¨æˆ·é€‰æ‹©è®¾ç½®è¾“å‡ºæ–‡ä»¶å
    if user_choice["mode"] == "specific_rank_async":
        output_path = os.path.join(output_dir, f"citation_analysis_rank_{user_choice['specific_rank']}_async_results.json")
    elif user_choice["mode"] == "head":
        output_path = os.path.join(output_dir, f"citation_analysis_head_{user_choice['num_samples']}_results.json")
    elif user_choice["mode"] == "start_from_async":
        if user_choice.get("num_samples"):
            output_path = os.path.join(output_dir, f"citation_analysis_from_{user_choice['start_from']}_count_{user_choice['num_samples']}_async_results.json")
        else:
            output_path = os.path.join(output_dir, f"citation_analysis_from_{user_choice['start_from']}_to_end_async_results.json")
    else:
        output_path = os.path.join(output_dir, "citation_analysis_method1_bailian_concurrent_results.json")

    print(f"ğŸš€ å¯åŠ¨é«˜é€Ÿå¹¶å‘åˆ†ææ¨¡å¼ï¼")
    print(f"è¾“å‡ºæ–‡ä»¶ï¼š{output_path}")

    # æ ¹æ®ç”¨æˆ·é€‰æ‹©è°ƒç”¨ä¸åŒçš„åˆ†ææ–¹æ³•
    if user_choice["mode"] == "specific_rank_async":
        results = await analyzer.batch_analyze_concurrent(excel_path, specific_rank=user_choice["specific_rank"])
    elif user_choice["mode"] == "head":
        results = await analyzer.batch_analyze_concurrent(excel_path, num_samples=user_choice["num_samples"])
    elif user_choice["mode"] == "start_from_async":
        results = await analyzer.batch_analyze_concurrent(excel_path, 
                                                         num_samples=user_choice.get("num_samples"),
                                                         start_from=user_choice["start_from"])
    else:  # "all"
        results = await analyzer.batch_analyze_concurrent(excel_path, num_samples=None)

    if results:
        analyzer.save_results(results, output_path)
        print(f"\nğŸ‰ å¹¶å‘åˆ†æå®Œæˆï¼")

        # æ˜¾ç¤ºæˆåŠŸçš„ç»“æœé¢„è§ˆ
        success_results = [r for r in results if r['api_success']]
        if success_results:
            print(f"\næˆåŠŸåˆ†æç¤ºä¾‹ï¼š")
            for i, result in enumerate(success_results[:1]):
                print(f"\n{i + 1}. ç¬¬{result['rank']}æ¡æ•°æ®:")
                print(f"   ä½¿ç”¨å¼•ç”¨: {result['citations_used']}")
                print(f"   å¯ç”¨å¼•æ–‡: {len(result['citations_available'])}ä¸ª")
                if result['analysis']:
                    print(f"   åˆ†æç‰‡æ®µ: {result['analysis'][:150]}...")
    else:
        print("åˆ†æå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®æ–‡ä»¶å’ŒAL_KEYé…ç½®")


# ä¿ç•™åŸæ¥çš„å‡½æ•°åä½œä¸ºåˆ«å
async def main_async():
    """å¼‚æ­¥å¹¶å‘ç‰ˆæœ¬çš„ä¸»å‡½æ•°ï¼ˆå…¼å®¹æ€§ä¿ç•™ï¼‰"""
    user_choice = {"mode": "all"}
    await main_async_impl(user_choice)


def main():
    """äº¤äº’å¼ä¸»å‡½æ•°"""
    # è·å–ç”¨æˆ·é€‰æ‹©
    user_choice = get_user_choice()
    if user_choice["mode"] == "exit":
        return

    analyzer = Method1BailianAnalyzer()

    # è·å–é¡¹ç›®æ ¹ç›®å½•è·¯å¾„
    script_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(os.path.dirname(script_dir))
    
    # æ•°æ®è·¯å¾„
    excel_path = os.path.join(project_root, "data", "input", "æ­£æ–‡å¼•æ–‡å†…å®¹ï¼ˆçº¯å‡€ç‰ˆï¼‰.xlsx")
    output_dir = os.path.join(project_root, "data", "output", "results")
    os.makedirs(output_dir, exist_ok=True)

    # æ ¹æ®ç”¨æˆ·é€‰æ‹©è®¾ç½®è¾“å‡ºæ–‡ä»¶å
    if user_choice["mode"] == "specific_rank":
        output_path = os.path.join(output_dir, f"citation_analysis_rank_{user_choice['specific_rank']}_sync_results.json")
    elif user_choice["mode"] == "start_from":
        if user_choice.get("num_samples"):
            output_path = os.path.join(output_dir, f"citation_analysis_from_{user_choice['start_from']}_count_{user_choice['num_samples']}_sync_results.json")
        else:
            output_path = os.path.join(output_dir, f"citation_analysis_from_{user_choice['start_from']}_to_end_sync_results.json")
    elif user_choice["mode"] == "head":
        output_path = os.path.join(output_dir, f"citation_analysis_head_{user_choice['num_samples']}_sync_results.json")
    else:
        output_path = os.path.join(output_dir, "citation_analysis_method1_bailian_sync_results.json")

    print(f"å¼€å§‹åŒæ­¥åˆ†æ...")
    print(f"è¾“å‡ºæ–‡ä»¶ï¼š{output_path}")

    # æ ¹æ®ç”¨æˆ·é€‰æ‹©è°ƒç”¨ä¸åŒçš„åˆ†ææ–¹æ³•
    if user_choice["mode"] == "specific_rank":
        results = analyzer.batch_analyze(excel_path, specific_rank=user_choice["specific_rank"])
    elif user_choice["mode"] == "start_from":
        results = analyzer.batch_analyze(excel_path,
                                         num_samples=user_choice.get("num_samples"),
                                         start_from=user_choice["start_from"])
    else:  # "all" or "head"
        results = analyzer.batch_analyze(excel_path, num_samples=user_choice.get("num_samples"))

    if results:
        analyzer.save_results(results, output_path)
        print(f"\næ–¹æ¡ˆ1ç™¾ç‚¼ç‰ˆåˆ†æå®Œæˆï¼")

        # æ˜¾ç¤ºæˆåŠŸçš„ç»“æœé¢„è§ˆ
        success_results = [r for r in results if r['api_success']]
        if success_results:
            print(f"\næˆåŠŸåˆ†æç¤ºä¾‹ï¼š")
            for i, result in enumerate(success_results[:1]):
                print(f"\n{i + 1}. ç¬¬{result['rank']}æ¡æ•°æ®:")
                print(f"   ä½¿ç”¨å¼•ç”¨: {result['citations_used']}")
                print(f"   å¯ç”¨å¼•æ–‡: {len(result['citations_available'])}ä¸ª")
                if result['analysis']:
                    print(f"   åˆ†æç‰‡æ®µ: {result['analysis'][:150]}...")
    else:
        print("åˆ†æå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®æ–‡ä»¶å’ŒAL_KEYé…ç½®")


if __name__ == "__main__":
    # è¿è¡Œç»Ÿä¸€ä¸»å‡½æ•°ï¼Œæ ¹æ®ç”¨æˆ·é€‰æ‹©è‡ªåŠ¨å†³å®šåŒæ­¥æˆ–å¼‚æ­¥
    main_unified()